{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*-Encoding: utf-8 -*-\n",
    "import numpy as np\n",
    "import torch\n",
    "from functools import partial\n",
    "from inspect import isfunction\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from .resnet import Res12_Quadratic\n",
    "\n",
    "\n",
    "def get_beta_schedule(beta_schedule, beta_start, beta_end, num_diffusion_timesteps):\n",
    "    if beta_schedule == 'quad':\n",
    "      betas = np.linspace(beta_start ** 0.5, beta_end ** 0.5, num_diffusion_timesteps, dtype=np.float64) ** 2\n",
    "    elif beta_schedule == 'linear':\n",
    "      betas = np.linspace(beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64)\n",
    "    elif beta_schedule == 'const':\n",
    "      betas = beta_end * np.ones(num_diffusion_timesteps, dtype=np.float64)\n",
    "    elif beta_schedule == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "      betas = 1. / np.linspace(num_diffusion_timesteps, 1, num_diffusion_timesteps, dtype=np.float64)\n",
    "    else:\n",
    "      raise NotImplementedError(beta_schedule)\n",
    "    assert betas.shape == (num_diffusion_timesteps,)\n",
    "    return betas\n",
    "\n",
    "\n",
    "def default(val, d):\n",
    "    if val is not None:\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n",
    "\n",
    "\n",
    "def extract(a, t, x_shape):\n",
    "    #print(a.shape, t.shape)\n",
    "    b, *_ = t.shape\n",
    "    out = a.gather(-1, t)\n",
    "    #print(out.shape)\n",
    "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "\n",
    "\n",
    "def noise_like(shape, device, repeat=False):\n",
    "    repeat_noise = lambda: torch.randn((1, *shape[1:]), device=device).repeat(\n",
    "        shape[0], *((1,) * (len(shape) - 1))\n",
    "    )\n",
    "    noise = lambda: torch.randn(shape, device=device)\n",
    "    return repeat_noise() if repeat else noise()\n",
    "\n",
    "\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        bvae,\n",
    "        input_size,\n",
    "        beta_start=0,\n",
    "        beta_end=0.1,\n",
    "        diff_steps=100,\n",
    "        betas=None,\n",
    "        scale = 0.1,\n",
    "        beta_schedule=\"linear\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.generative = bvae\n",
    "        self.scale = scale\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        betas = get_beta_schedule(beta_schedule, beta_start, beta_end, diff_steps)\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "\n",
    "        alphas_target = 1.0 - betas*scale\n",
    "        alphas_target_cumprod = np.cumprod(alphas_target, axis=0)\n",
    "        self.alphas_target = alphas_target\n",
    "        self.alphas_target_cumprod = alphas_target_cumprod\n",
    "\n",
    "        (timesteps,) = betas.shape\n",
    "        self.num_timesteps = int(timesteps)\n",
    "\n",
    "        to_torch = partial(torch.tensor, dtype=torch.float32)\n",
    "        self.register_buffer(\"betas\", to_torch(betas))\n",
    "        self.register_buffer(\"alphas_cumprod\", to_torch(alphas_cumprod))\n",
    "\n",
    "        self.register_buffer(\"sqrt_alphas_cumprod\", to_torch(np.sqrt(alphas_cumprod)))\n",
    "        self.register_buffer(\"sqrt_alphas_target_cumprod\", to_torch(np.sqrt(alphas_target_cumprod)))\n",
    "        self.register_buffer(\n",
    "            \"sqrt_one_minus_alphas_cumprod\", to_torch(np.sqrt(1.0 - alphas_cumprod))\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"sqrt_one_minus_alphas_target_cumprod\", to_torch(np.sqrt(1.0 - alphas_target_cumprod))\n",
    "        )\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "        return (\n",
    "            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start\n",
    "            + extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise\n",
    "        )\n",
    "\n",
    "    def q_sample_target(self, y_target, t, noise=None):\n",
    "        noise = default(noise, lambda: torch.randn_like(y_target))\n",
    "\n",
    "        return (\n",
    "            extract(self.sqrt_alphas_target_cumprod, t, y_target.shape) * y_target\n",
    "            + extract(self.sqrt_one_minus_alphas_target_cumprod, t, y_target.shape) * noise\n",
    "        )\n",
    "\n",
    "    def p_losses(self, x_start, y_target, t,  noise=None, noise1=None):\n",
    "        B, T, _ = x_start.shape\n",
    "        B1, T1, _ = y_target.shape\n",
    "        x_start = x_start.reshape(B, 1, T, -1)\n",
    "        y_target = y_target.reshape(B1, 1, T1, -1)\n",
    "\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "        noise1 = default(noise1, lambda: torch.randn_like(y_target))\n",
    "\n",
    "        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise.to(x_start.device))\n",
    "\n",
    "        y_noisy = self.q_sample_target(y_target=y_target, t=t, noise=noise1.to(y_target.device))\n",
    "        x_noisy = x_noisy.reshape(B,1, T,-1)\n",
    "\n",
    "        y_noisy = y_noisy.reshape(B1,1, T1,-1)\n",
    "\n",
    "        logits = self.generative(x_noisy)\n",
    "\n",
    "        output = self.generative.decoder_output(logits)\n",
    "        return output, y_noisy\n",
    "\n",
    "    def log_prob(self, x_input, y_target, time):\n",
    "        output, y_noisy = self.p_losses(\n",
    "            x_input, y_target, time,\n",
    "        )\n",
    "        return output, y_noisy\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
