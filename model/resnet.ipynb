{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9186ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*-Encoding: utf-8 -*-\n",
    "from torch import nn\n",
    "from torch.autograd import grad\n",
    "import torch\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        m.weight.data.normal_(0.0, 0.2)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        m.weight.data.normal_(1.0, 0.2)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "class MyConvo2d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size,  stride = 1, bias = True):\n",
    "        super(MyConvo2d, self).__init__()\n",
    "        self.padding = int((kernel_size - 1)/2)\n",
    "        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size, stride=1, padding=self.padding, bias = bias)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Square(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Square,self).__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self,in_vect):\n",
    "        return in_vect**2\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Swish,self).__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self,in_vect):\n",
    "        return in_vect*nn.functional.sigmoid(in_vect)\n",
    "\n",
    "\n",
    "class MeanPoolConv(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size):\n",
    "        super(MeanPoolConv, self).__init__()\n",
    "        self.conv = MyConvo2d(input_dim, output_dim, kernel_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = input\n",
    "        output = self.conv(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class ConvMeanPool(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size):\n",
    "        super(ConvMeanPool, self).__init__()\n",
    "        self.conv = MyConvo2d(input_dim, output_dim, kernel_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size, hw, resample=None, normalize=False,AF=nn.ELU()):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.resample = resample\n",
    "        self.normalize = normalize\n",
    "        self.bn1 = None\n",
    "        self.bn2 = None\n",
    "        self.relu1 = AF\n",
    "        self.relu2 = AF\n",
    "        if resample == 'down':\n",
    "            self.bn1 = nn.LayerNorm([input_dim, hw, hw])\n",
    "            self.bn2 = nn.LayerNorm([input_dim, hw, hw])\n",
    "        elif resample == 'none':\n",
    "            self.bn1 = nn.LayerNorm([input_dim, hw, hw])\n",
    "            self.bn2 = nn.LayerNorm([input_dim, hw, hw])\n",
    "\n",
    "        if resample == 'down':\n",
    "            self.conv_shortcut = MeanPoolConv(input_dim, output_dim, kernel_size = 1)\n",
    "            self.conv_1 = MyConvo2d(input_dim, input_dim, kernel_size = kernel_size, bias = False)\n",
    "            self.conv_2 = ConvMeanPool(input_dim, output_dim, kernel_size = kernel_size)\n",
    "        elif resample == 'none':\n",
    "            self.conv_shortcut = MyConvo2d(input_dim, output_dim, kernel_size = 1)\n",
    "            self.conv_1 = MyConvo2d(input_dim, input_dim, kernel_size = kernel_size, bias = False)\n",
    "            self.conv_2 = MyConvo2d(input_dim, output_dim, kernel_size = kernel_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.input_dim == self.output_dim and self.resample == None:\n",
    "                shortcut = input\n",
    "        else:\n",
    "            shortcut = self.conv_shortcut(input)\n",
    "\n",
    "        if self.normalize == False:\n",
    "            output = input\n",
    "            output = self.relu1(output)\n",
    "            output = self.conv_1(output)\n",
    "            output = self.relu2(output)\n",
    "            output = self.conv_2(output)\n",
    "        else:\n",
    "            output = input\n",
    "            output = self.bn1(output)\n",
    "            output = self.relu1(output)\n",
    "            output = self.conv_1(output)\n",
    "            output = self.bn2(output)\n",
    "            output = self.relu2(output)\n",
    "            output = self.conv_2(output)\n",
    "\n",
    "        return shortcut + output\n",
    "\n",
    "\n",
    "class Res12_Quadratic(nn.Module):\n",
    "    def __init__(self,inchan,dim,hw,normalize=False,AF=None):\n",
    "        super(Res12_Quadratic, self).__init__()\n",
    "\n",
    "        self.hw = hw\n",
    "        self.dim = dim\n",
    "        self.inchan = inchan\n",
    "        self.conv1 = MyConvo2d(inchan,dim, 3)\n",
    "        self.rb1 = ResidualBlock(dim, 2*dim, 3, int(hw), resample = 'down',normalize=normalize,AF=AF)\n",
    "        self.rbc1 = ResidualBlock(2*dim, 2*dim, 3, int(hw/2), resample = 'none',normalize=normalize,AF=AF)\n",
    "        self.rb2 = ResidualBlock(2*dim, 4*dim, 3, int(hw/2), resample = 'down',normalize=normalize,AF=AF)\n",
    "        self.rbc2 = ResidualBlock(4*dim, 4*dim, 3, int(hw/4), resample = 'none',normalize=normalize,AF=AF)\n",
    "        self.rb3 = ResidualBlock(4*dim, 8*dim, 3, int(hw/4), resample = 'down',normalize=normalize,AF=AF)\n",
    "        self.rbc3 = ResidualBlock(8*dim, 8*dim, 3, int(hw/8), resample = 'none',normalize=normalize,AF=AF)\n",
    "        self.ln1 = nn.Linear(int(hw/8)*int(hw/8)*8*dim, 1)\n",
    "        self.ln2 = nn.Linear(int(hw/8)*int(hw/8)*8*dim, 1)\n",
    "        self.lq = nn.Linear(int(hw/8)*int(hw/8)*8*dim, 1)\n",
    "        self.Square = Square()\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        output = x_in\n",
    "        output = self.conv1(output)\n",
    "        # print(output.shape)\n",
    "        output = self.rb1(output)\n",
    "        output = self.rbc1(output)\n",
    "        output = self.rb2(output)\n",
    "        output = self.rbc2(output)\n",
    "        output = self.rb3(output)\n",
    "        output = self.rbc3(output)\n",
    "        output = output.view(-1, int(self.hw/8)*int(self.hw/8)*8*self.dim)\n",
    "        output = self.ln1(output)*self.ln2(output)+self.lq(self.Square(output))\n",
    "        output = output.view(-1)\n",
    "        return output\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
