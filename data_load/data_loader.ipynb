{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bacc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*-Encoding: utf-8 -*-\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.timefeatures import time_features\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class StandardScaler(object):\n",
    "    def __init__(self):\n",
    "        self.mean = 0.\n",
    "        self.std = 1.\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.mean = data.mean(0)\n",
    "        self.std = data.std(0)\n",
    "\n",
    "    def transform(self, data):\n",
    "        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n",
    "        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n",
    "        return (data - mean) / std\n",
    "\n",
    "\n",
    "class Dataset_Custom(Dataset):\n",
    "    def __init__(self, root_path, flag='train', size=None, data_path='AAPL.csv'):\n",
    "        # size [seq_len, label_len, pred_len]\n",
    "        # info\n",
    "        self.seq_len = size[0]\n",
    "        self.pred_len = size[1]\n",
    "        # init\n",
    "        assert flag in ['train', 'test', 'val']\n",
    "        type_map = {'train':0, 'val':1, 'test':2}\n",
    "        self.set_type = type_map[flag]\n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.data_path = data_path\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df_raw = pd.read_csv(os.path.join(self.root_path, self.data_path))\n",
    "        length = len( df_raw)\n",
    "        num_train = int(length*0.7)\n",
    "        num_test = int(length*0.2)\n",
    "        num_vali = int(length*0.1)\n",
    "\n",
    "        border1s = [0, num_train-self.seq_len, num_train+num_vali-self.seq_len]\n",
    "        border2s = [num_train, num_train+num_vali, num_train+num_vali+num_test]\n",
    "        border1 = border1s[self.set_type]\n",
    "        border2 = border2s[self.set_type]\n",
    "\n",
    "        cols_data = df_raw.columns[1:]\n",
    "        df_data = df_raw[cols_data]\n",
    "\n",
    "        train_data = df_data[border1s[0]:border2s[0]]\n",
    "        self.scaler.fit(train_data.values)\n",
    "        data = self.scaler.transform(df_data.values)\n",
    "\n",
    "        df_stamp = pd.DatetimeIndex(df_raw[border1:border2]['date'])\n",
    "        data_stamp = time_features(df_stamp)\n",
    "\n",
    "        self.data_x = data[border1:border2]\n",
    "        self.data_y = data[border1:border2]\n",
    "        self.data_stamp = data_stamp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end\n",
    "        r_end = r_begin + self.pred_len\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end, -1:]\n",
    "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "\n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
