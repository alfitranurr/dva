{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55757f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*-Encoding: utf-8 -*-\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from exp.exp_model import Exp_Model\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "fix_seed = 100\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='generating')\n",
    "\n",
    "# Load data\n",
    "parser.add_argument('--root_path', type=str, default='./data/2016', help='root path of the data files')\n",
    "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n",
    "parser.add_argument('--sequence_length', type=int, default=10, help='length of input sequence')\n",
    "parser.add_argument('--prediction_length', type=int, default=None, help='prediction sequence length')\n",
    "parser.add_argument('--target_dim', type=int, default=1, help='dimension of target')\n",
    "parser.add_argument('--input_dim', type=int, default=6, help='dimension of input')\n",
    "parser.add_argument('--hidden_size', type=int, default=128, help='encoder dimension')\n",
    "parser.add_argument('--embedding_dimension', type=int, default=64, help='feature embedding dimension')\n",
    "\n",
    "# Diffusion process\n",
    "parser.add_argument('--diff_steps', type=int, default=1000, help='number of the diff step')\n",
    "parser.add_argument('--dropout_rate', type=float, default=0.1, help='dropout')\n",
    "parser.add_argument('--beta_schedule', type=str, default='linear', help='the schedule of beta')\n",
    "parser.add_argument('--beta_start', type=float, default=0.0, help='start of the beta')\n",
    "parser.add_argument('--beta_end', type=float, default=1.0, help='end of the beta')\n",
    "parser.add_argument('--scale', type=float, default=0.1, help='adjust diffusion scale')\n",
    "\n",
    "# Bidirectional VAE\n",
    "parser.add_argument('--arch_instance', type=str, default='res_mbconv', help='path to the architecture instance')\n",
    "parser.add_argument('--mult', type=float, default=1, help='mult of channels')\n",
    "parser.add_argument('--num_layers', type=int, default=2, help='num of RNN layers')\n",
    "parser.add_argument('--num_channels_enc', type=int, default=32, help='number of channels in encoder')\n",
    "parser.add_argument('--channel_mult', type=int, default=2, help='number of channels in encoder')\n",
    "parser.add_argument('--num_preprocess_blocks', type=int, default=1, help='number of preprocessing blocks')\n",
    "parser.add_argument('--num_preprocess_cells', type=int, default=3, help='number of cells per block')\n",
    "parser.add_argument('--groups_per_scale', type=int, default=2, help='number of cells per block')\n",
    "parser.add_argument('--num_postprocess_blocks', type=int, default=1, help='number of postprocessing blocks')\n",
    "parser.add_argument('--num_postprocess_cells', type=int, default=2, help='number of cells per block')\n",
    "parser.add_argument('--num_channels_dec', type=int, default=32, help='number of channels in decoder')\n",
    "parser.add_argument('--num_latent_per_group', type=int, default=8, help='number of channels in latent variables per group')\n",
    "\n",
    "# Training settings\n",
    "parser.add_argument('--num_workers', type=int, default=5, help='data loader num workers')\n",
    "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')\n",
    "parser.add_argument('--itr', type=int, default=5, help='experiment times')\n",
    "parser.add_argument('--train_epochs', type=int, default=20, help='train epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=16, help='batch size of train input data')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0005, help='optimizer learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=0.0000, help='weight decay')\n",
    "parser.add_argument('--zeta', type=float, default=0.5, help='trade off parameter zeta')\n",
    "parser.add_argument('--eta', type=float, default=1.0, help='trade off parameter eta')\n",
    "\n",
    "# Device\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.prediction_length is None:\n",
    "    args.prediction_length = args.sequence_length\n",
    "\n",
    "print('Args in experiment:')\n",
    "print(args)\n",
    "\n",
    "Exp = Exp_Model\n",
    "results = pd.DataFrame(columns=['Ticker', 'MSE', 'StdDev'])\n",
    "train_setting = 'tp{}_sl{}'.format(args.root_path.split(os.sep)[-1], args.sequence_length)\n",
    "\n",
    "for idx, file in enumerate(os.listdir(args.root_path)): # Iterate through all tickers\n",
    "    print('\\n\\nRunning on file {} ({}/{})...'.format(file, idx+1, len(os.listdir(args.root_path))))\n",
    "    args.data_path = file\n",
    "    ticker = os.path.splitext(file)[0]\n",
    "    all_mse = []\n",
    "\n",
    "    for ii in range(0, args.itr):\n",
    "        setting = args.data_path + '_' + train_setting\n",
    "        exp = Exp(args)  # single experiment\n",
    "        print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "        exp.train(setting)\n",
    "        print('>>>>>>>start testing : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "        mse = exp.test(setting)\n",
    "        all_mse.append(mse)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    results = results.append({'Ticker': ticker, 'MSE': np.mean(np.array(all_mse)), 'StdDev': np.std(np.array(all_mse))}, ignore_index=True)\n",
    "\n",
    "folder_path = './results/'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "results.to_csv(folder_path + train_setting + '.csv', index=False)\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
